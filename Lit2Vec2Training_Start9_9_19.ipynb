{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lit2Vec2Training-Start9-9-19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V62piRJV2azh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c786953c-057c-443a-f3a9-085b5cd9e5ea"
      },
      "source": [
        "!pip install LogUniform"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: LogUniform in /usr/local/lib/python3.6/dist-packages (1.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz8FsZRH99zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "import time\n",
        "\n",
        "import loguniform\n",
        "from loguniform import LogUniform\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from __future__ import print_function\n",
        "import collections\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import zipfile\n",
        "import os\n",
        "import requests\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "from os.path import isfile, isdir\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from matplotlib import pylab\n",
        "from six.moves import range\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "\n",
        "from numpy import genfromtxt\n",
        "import sys\n",
        "\n",
        "numbBooks = 2829853+1 #according to https://github.com/zygmuntz/goodbooks-10k there are 10000 books in the dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7pnzPPq0okb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fub14Dc60_kJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download_file_from_google_drive('1w3uSNtc1srNaWoRHwbUE9o3baokloh9U', 'books.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChkL1wlL4s3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dl_id = input(\"Enter Gdrive file ID for books: \") \n",
        "\n",
        "# dl_id =  '1w3uSNtc1srNaWoRHwbUE9o3baokloh9U'\n",
        "\n",
        "# # DOWNLOAD ZIP\n",
        "# print (\"Downloading  file\")\n",
        "# myzip = drive.CreateFile({'id': dl_id})\n",
        "# myzip.GetContentFile('books.csv')\n",
        "\n",
        "# print( os.listdir() )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkAhaGQZ4uOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# b = pd.read_csv( 'books.csv' )\n",
        "# b.head(30)\n",
        "# bookDictionary = b.set_index('book_id').to_dict()['original_title']\n",
        "# bookDictionary[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkf7DrmN-Jmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download_file_from_google_drive('1lH-0JqQ4UwgL-k83w9xrfftHzvx54phy', 'GoodReadsUser4MS.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn_r-hAt8JP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "openHdf = pd.read_hdf('GoodReadsUser4MS.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dDUtTm18ben",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f579b326-9caf-4c05-f4b8-61a2c14bf380"
      },
      "source": [
        "openHdf.loc[180:220]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>EmbedID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>1</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>1</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>1</td>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>1</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>1</td>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>1</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>1</td>\n",
              "      <td>186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>1</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>1</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>1</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>1</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>1</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>1</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>1</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>1</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>1</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>1</td>\n",
              "      <td>199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>2</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>2</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>2</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>2</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>2</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>2</td>\n",
              "      <td>203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>2</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>2</td>\n",
              "      <td>205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>2</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>2</td>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>2</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>2</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>2</td>\n",
              "      <td>209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>2</td>\n",
              "      <td>210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>2</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>2</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>2</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>2</td>\n",
              "      <td>214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>2</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     UserID  EmbedID\n",
              "180       1      180\n",
              "181       1      181\n",
              "182       1      182\n",
              "183       1      183\n",
              "184       1      184\n",
              "185       1      185\n",
              "186       1      186\n",
              "187       1      187\n",
              "188       1      188\n",
              "189       1      189\n",
              "190       1      190\n",
              "191       1      191\n",
              "192       1      192\n",
              "193       1      193\n",
              "194       1      194\n",
              "195       1      195\n",
              "196       1      196\n",
              "197       1      197\n",
              "198       1      198\n",
              "199       1      199\n",
              "200       2      102\n",
              "201       2      200\n",
              "202       2      201\n",
              "203       2      202\n",
              "204       2       92\n",
              "205       2      203\n",
              "206       2      204\n",
              "207       2      205\n",
              "208       2      113\n",
              "209       2      206\n",
              "210       2      207\n",
              "211       2      208\n",
              "212       2      209\n",
              "213       2      210\n",
              "214       2      211\n",
              "215       2      212\n",
              "216       2      147\n",
              "217       2      192\n",
              "218       2      213\n",
              "219       2      214\n",
              "220       2      215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Df7jhFY8bbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_data = openHdf.groupby('UserID')['EmbedID'].apply(list).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL5Q7L628uEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "6f046bf2-acd7-4516-b4a8-92897f4bbb78"
      },
      "source": [
        "my_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]),\n",
              "       list([102, 200, 201, 202, 92, 203, 204, 205, 113, 206, 207, 208, 209, 210, 211, 212, 147, 192, 213, 214, 215, 216, 217, 218, 219, 166, 220, 221, 222, 223, 224, 225, 226, 227, 188, 168, 228, 229, 230, 231, 232, 233, 70, 234, 235, 236, 237, 154]),\n",
              "       list([238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 42, 254, 255, 256, 257, 258, 259, 260]),\n",
              "       ..., list([27, 8331, 207, 2372]),\n",
              "       list([94, 223, 207, 109, 2958, 1574, 6090, 201, 84, 2437, 1211, 4944, 525, 2152, 10033, 710, 92, 635, 1187, 930, 35, 4437, 91, 2239, 1730, 3068, 27, 134, 1109, 2642, 989, 925, 2235, 3139, 646, 159, 11418, 218, 1290, 1095, 3005]),\n",
              "       list([1043, 2958, 2372, 164942, 2395, 67811, 94, 13963, 2399, 154, 8254, 2397, 9702, 506, 2068, 9731, 419669, 2437, 1190051, 92, 2478, 3453, 524766, 29261, 69349, 143, 2651, 920, 42706, 3468, 27, 8546, 559])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiV61IrdPg_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del openHdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE2HW6llJZtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_index = 0\n",
        "epoch_index = 0\n",
        "# recEpoch_indexA = 0 #Used to help keep store of the total number of epoches with the models\n",
        "\n",
        "d1 = LogUniform(a=1, b=numbBooks)\n",
        "\n",
        "def generate_batch(batch_size, posRate, negRate): \n",
        "  \n",
        "    global data_index, epoch_index\n",
        "    \n",
        "    batch = np.zeros(shape=(batch_size, posRate), dtype=np.int32) \n",
        "    labels = np.zeros(shape=(batch_size, 1), dtype=np.int32)\n",
        "    negs = np.zeros(shape=(batch_size, negRate), dtype=np.int32)\n",
        "\n",
        "    n=0\n",
        "    while n < batch_size:\n",
        "        firstpick = np.random.choice( len(my_data[data_index]), 1)[0]\n",
        "        labels[n] = my_data[data_index][firstpick]\n",
        "        batchSet = my_data[data_index][:firstpick]+my_data[data_index][firstpick+1:]\n",
        "        batch[n] = np.random.choice( batchSet , posRate)\n",
        "        excludes = np.concatenate( (labels[n], batch[n]), axis=None)\n",
        "\n",
        "        criterea0 = 0\n",
        "        while criterea0 < negRate: #just in case \n",
        "            aa = d1.rvs(negRate*3).astype(int) \n",
        "            # aa = d1.rvs(negRate*4).astype(int) -1\n",
        "            sampleCandidates = np.setdiff1d( aa, excludes )\n",
        "            criterea0 = sampleCandidates.shape[0]\n",
        "\n",
        "        negs[n] = np.random.choice( sampleCandidates, negRate, replace=False)\n",
        "\n",
        "        n = n+1\n",
        "        data_index = (data_index + 1) % len(my_data) #may have to do something like len my_data[:]\n",
        "        if data_index == 0:\n",
        "            epoch_index = epoch_index + 1\n",
        "            print('Completed %d Epochs' % epoch_index)\n",
        "    \n",
        "    return batch, labels, negs    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DsXP9kb8DE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e90abeaa-39a1-45ad-a486-f440d5cef88b"
      },
      "source": [
        "here, goes, negs = generate_batch(20, 2, 3) \n",
        "print('batch', here)\n",
        "print('labels', goes)\n",
        "print('negs', negs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch [[  91  131]\n",
            " [ 147  235]\n",
            " [ 238  238]\n",
            " [ 261  124]\n",
            " [ 338  313]\n",
            " [ 458  459]\n",
            " [ 467  472]\n",
            " [ 529  491]\n",
            " [ 563  579]\n",
            " [ 627  620]\n",
            " [ 651  656]\n",
            " [ 662  662]\n",
            " [ 688  716]\n",
            " [ 143  736]\n",
            " [ 773  745]\n",
            " [ 776  776]\n",
            " [ 873  833]\n",
            " [ 917  911]\n",
            " [ 944  941]\n",
            " [1001  967]]\n",
            "labels [[ 49]\n",
            " [210]\n",
            " [260]\n",
            " [262]\n",
            " [345]\n",
            " [454]\n",
            " [474]\n",
            " [519]\n",
            " [575]\n",
            " [619]\n",
            " [653]\n",
            " [661]\n",
            " [680]\n",
            " [210]\n",
            " [ 72]\n",
            " [777]\n",
            " [842]\n",
            " [914]\n",
            " [949]\n",
            " [956]]\n",
            "negs [[     58  882631   30456]\n",
            " [   7622  866625   53365]\n",
            " [    177 1070178   22946]\n",
            " [1199920  452648      89]\n",
            " [ 218939       8    2914]\n",
            " [     33     541   59866]\n",
            " [     15     541    2735]\n",
            " [    277 1670320      46]\n",
            " [   1170  311616    1844]\n",
            " [      1      11    1205]\n",
            " [   8390   72898       7]\n",
            " [    198       2    1796]\n",
            " [ 262039  520751  418196]\n",
            " [ 240385 2580133     234]\n",
            " [      2     416     348]\n",
            " [      4  185514 1771730]\n",
            " [     64       4 2023280]\n",
            " [ 131648  723777     129]\n",
            " [  42188       2      19]\n",
            " [ 427173  182536      21]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN8lEIKJxmRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SkipGramModel(nn.Module):\n",
        "    \"\"\"Skip gram model of word2vec.\n",
        "    Attributes:\n",
        "        emb_size: Embedding size.\n",
        "        emb_dimention: Embedding dimention, typically from 50 to 500.\n",
        "        u_embedding: Embedding for center word.\n",
        "        v_embedding: Embedding for neibor words.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, batchSize, skipWindow):\n",
        "        \"\"\"Initialize model parameters.\n",
        "        Apply for two embedding layers.\n",
        "        Initialize layer weight\n",
        "        Args:\n",
        "            emb_size: Embedding size.\n",
        "            emb_dimention: Embedding dimention, typically from 50 to 500.\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        super(SkipGramModel, self).__init__()\n",
        "        self.emb_size = batchSize\n",
        "        self.skipWindow = skipWindow\n",
        "        self.emb_dimension = emb_dimension\n",
        "        self.batchSize = batchSize\n",
        "        self.u_embeddings = nn.Embedding(batchSize, emb_dimension, sparse=True).cuda()\n",
        "        self.v_embeddings = nn.Embedding( batchSize, emb_dimension, sparse=True).cuda()\n",
        "        # self.targets = torch.ones(34816).cud\n",
        "        self.init_emb()\n",
        "\n",
        "    def init_emb(self):\n",
        "        \"\"\"Initialize embedding weight like word2vec.\n",
        "        The u_embedding is a uniform distribution in [-0.5/em_size, 0.5/emb_size], and the elements of v_embedding are zeroes.\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        initrange = (2.0 / (numbBooks + self.emb_dimension)) ** 0.5 # Xavier init\n",
        "        self.u_embeddings.weight.data.uniform_(-initrange, initrange)\n",
        "        self.v_embeddings.weight.data.normal_(mean=0, std=math.sqrt(initrange))\n",
        "        self.lossFunction = nn.BCEWithLogitsLoss( reduction = 'none' )\n",
        "\n",
        "    def forward(self, pos_u, pos_v, neg_v, targets ):\n",
        "        \"\"\"Forward process.\n",
        "        As pytorch designed, all variables must be batch format, so all input of this method is a list of word id.\n",
        "        Args:\n",
        "            pos_u: list of center word ids for positive word pairs.\n",
        "            pos_v: list of neibor word ids for positive word pairs.\n",
        "            neg_u: list of center word ids for negative word pairs.\n",
        "            neg_v: list of neibor word ids for negative word pairs.\n",
        "        Returns:\n",
        "            Loss of this process, a pytorch variable.\n",
        "        \"\"\"\n",
        "        emb_u = self.u_embeddings(pos_u)\n",
        "        emb_v = self.v_embeddings(pos_v)\n",
        "        neg_emb_v = self.v_embeddings(neg_v)\n",
        "\n",
        "        scorePos = torch.bmm(emb_u, torch.transpose(emb_v, 1, 2)).squeeze()\n",
        "        scoreNeg = torch.bmm( emb_u , torch.transpose(neg_emb_v, 1, 2) ).squeeze()\n",
        "\n",
        "        #reduce to dot products for each set, and concatinate all the losses\n",
        "        #noticed that the sign change for the negative sample dot products\n",
        "        totalScores = torch.cat( ( scorePos.reshape(scorePos.shape[0], -1) , -scoreNeg.reshape(scoreNeg.shape[0], -1) ) , dim=1)\n",
        "\n",
        "        indLoss = self.lossFunction( totalScores, targets )\n",
        "        rowSum = torch.sum(indLoss, dim=1) #Sum all losses for each set\n",
        "        finalLoss = torch.mean(rowSum) #Average losses across batches \n",
        "\n",
        "        return finalLoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcf12Y-4x8OL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3773b578-0e56-4960-fd81-6b8832f54c9d"
      },
      "source": [
        "output_file_name = 'theOutpule.file'\n",
        "\n",
        "emb_dimension = 400\n",
        "batch_size = 256\n",
        "posRate = 4\n",
        "negRate = 128\n",
        "iterationsMax = 40000 #200001\n",
        "# initial_lr = 1.0\n",
        "\n",
        "skip_gram_model = SkipGramModel(batch_size*(2*posRate+negRate), emb_dimension)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('use cuda ? ', use_cuda)\n",
        "if use_cuda:\n",
        "    skip_gram_model.cuda()\n",
        "\n",
        "optimizer = optim.Adagrad(\n",
        "    skip_gram_model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "use cuda ?  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MGtvtYpPmou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y97O--DDPoju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cc78977-154d-468d-974b-e3a56e9dfd9e"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "207"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnhraRnEzpTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a66e59c2-563f-49e6-877b-4d4220e88e46"
      },
      "source": [
        "!pip install SpeedTorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeedTorch in /usr/local/lib/python3.6/dist-packages (0.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from SpeedTorch) (1.16.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from SpeedTorch) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knEYJP7TLn5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import SpeedTorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk_CnNcBACB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uEmbed_switcher = SpeedTorch.ModelFactory( skip_gram_model.u_embeddings, total_classes=numbBooks, embed_dimension=400 )\n",
        "vEmbed_switcher = SpeedTorch.ModelFactory( skip_gram_model.v_embeddings, total_classes=numbBooks, embed_dimension=400 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJI3MvoJABqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initrange = (2.0 / (numbBooks + emb_dimension)) ** 0.5 # Xavier init\n",
        "uEmbed_switcher.uniformDistributionInit( -initrange, initrange )\n",
        "vEmbed_switcher.normalDistributionInit( 0, math.sqrt(initrange) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1p5DYskLxAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uAdagrad_switcher = SpeedTorch.OptimizerFactory( optimizer, total_classes=numbBooks, embed_dimension=400, model=skip_gram_model, variable_name= 'u_embeddings', CPUPinn = True)\n",
        "vAdagrad_switcher = SpeedTorch.OptimizerFactory( optimizer, total_classes=numbBooks, embed_dimension=400, model=skip_gram_model, variable_name='v_embeddings' , CPUPinn = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoTu-2zmLw-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uAdagrad_switcher.optInit()\n",
        "vAdagrad_switcher.optInit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziXthZwjL1Jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "labelsDummyInput = uEmbed_switcher.variableTransformer( batchSize=batch_size, posPerBatch=1)\n",
        "batchDummpyInput, negzDummyInput = vEmbed_switcher.variableTransformer( batchSize=batch_size, posPerBatch=4, negPerBatch=128 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn9Zvv4PxtXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab6b4225-c2f6-4305-c9a4-81b18e62762b"
      },
      "source": [
        "runningLoss = 0\n",
        "runningStepTime = 0 \n",
        "negSamp = 128\n",
        "window_size = posRate\n",
        "\n",
        "targets = torch.ones( batch_size, window_size + negSamp , dtype = torch.float32 ).cuda()\n",
        "\n",
        "batchTensor = torch.from_numpy(batchDummpyInput)\n",
        "LabelTensor = torch.from_numpy(labelsDummyInput)\n",
        "negTensor = torch.from_numpy(negzDummyInput)\n",
        "\n",
        "pos_u = Variable(torch.LongTensor(LabelTensor.long()))\n",
        "pos_v = Variable(torch.LongTensor(batchTensor.long()))\n",
        "neg_v = Variable(torch.LongTensor(negTensor.long()))\n",
        "\n",
        "if use_cuda:\n",
        "    pos_u = pos_u.cuda()\n",
        "    pos_v = pos_v.cuda()\n",
        "    neg_v = neg_v.cuda()\n",
        "\n",
        "for i in range(1000000):\n",
        "    start = time.time()\n",
        "    batch, labels, negz = generate_batch(batch_size=batch_size, posRate=4, negRate= 128)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        uEmbed_switcher.beforeForwardPass( labels )\n",
        "        vEmbed_switcher.beforeForwardPass( batch, negz )\n",
        "        uAdagrad_switcher.beforeForwardPass( labels )\n",
        "        vAdagrad_switcher.beforeForwardPass( batch, negz )\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss = skip_gram_model.forward(pos_u, pos_v, neg_v, targets)\n",
        "    runningLoss = runningLoss + loss.data.item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        uEmbed_switcher.afterOptimizerStep( labels )\n",
        "        vEmbed_switcher.afterOptimizerStep( batch, negz )\n",
        "        uAdagrad_switcher.afterOptimizerStep( labels )\n",
        "        vAdagrad_switcher.afterOptimizerStep( batch, negz )\n",
        "\n",
        "    end = time.time()\n",
        "    runningStepTime = runningStepTime + end - start\n",
        "\n",
        "    if i%1000 == 0:\n",
        "        print('i is ', i)\n",
        "        print('loss is ', runningLoss/1000)\n",
        "        print('Average step time is ', runningStepTime/1000)\n",
        "        runningLoss = 0\n",
        "        runningStepTime = 0\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i is  52400\n",
            "loss is  25.44021614074707\n",
            "Average step time is  0.07218986511230469\n",
            "i is  52500\n",
            "loss is  24.706112003326417\n",
            "Average step time is  0.07175094604492188\n",
            "i is  52600\n",
            "loss is  24.208006343841554\n",
            "Average step time is  0.07194416284561157\n",
            "i is  52700\n",
            "loss is  24.235839786529542\n",
            "Average step time is  0.07187815189361572\n",
            "i is  52800\n",
            "loss is  24.177165851593017\n",
            "Average step time is  0.07203875064849853\n",
            "i is  52900\n",
            "loss is  24.288210258483886\n",
            "Average step time is  0.07186048984527588\n",
            "i is  53000\n",
            "loss is  24.202629585266113\n",
            "Average step time is  0.07172263860702514\n",
            "i is  53100\n",
            "loss is  24.121510677337646\n",
            "Average step time is  0.07126603364944457\n",
            "i is  53200\n",
            "loss is  24.20358549118042\n",
            "Average step time is  0.07123564720153809\n",
            "i is  53300\n",
            "loss is  24.186213817596435\n",
            "Average step time is  0.07180657148361207\n",
            "i is  53400\n",
            "loss is  23.910485401153565\n",
            "Average step time is  0.07178303480148315\n",
            "i is  53500\n",
            "loss is  24.145247116088868\n",
            "Average step time is  0.07169868707656861\n",
            "i is  53600\n",
            "loss is  24.146949100494385\n",
            "Average step time is  0.07200787305831909\n",
            "i is  53700\n",
            "loss is  24.207330474853517\n",
            "Average step time is  0.07193418264389038\n",
            "i is  53800\n",
            "loss is  23.939530200958252\n",
            "Average step time is  0.07170243740081787\n",
            "i is  53900\n",
            "loss is  24.035132083892822\n",
            "Average step time is  0.07143023490905762\n",
            "i is  54000\n",
            "loss is  24.087722549438478\n",
            "Average step time is  0.07161071062088013\n",
            "i is  54100\n",
            "loss is  24.386868591308595\n",
            "Average step time is  0.07150579452514648\n",
            "i is  54200\n",
            "loss is  24.30500524520874\n",
            "Average step time is  0.07191145181655884\n",
            "i is  54300\n",
            "loss is  24.77242370605469\n",
            "Average step time is  0.07151348829269409\n",
            "i is  54400\n",
            "loss is  24.334049739837646\n",
            "Average step time is  0.07160693168640136\n",
            "i is  54500\n",
            "loss is  24.63195680618286\n",
            "Average step time is  0.07159450531005859\n",
            "i is  54600\n",
            "loss is  24.965318450927736\n",
            "Average step time is  0.07176215171813966\n",
            "i is  54700\n",
            "loss is  24.968970165252685\n",
            "Average step time is  0.07170820236206055\n",
            "Completed 10 Epochs\n",
            "i is  54800\n",
            "loss is  26.343589420318605\n",
            "Average step time is  0.07203551054000855\n",
            "i is  54900\n",
            "loss is  25.390784873962403\n",
            "Average step time is  0.07177867650985718\n",
            "i is  55000\n",
            "loss is  25.67910873413086\n",
            "Average step time is  0.07194515228271485\n",
            "i is  55100\n",
            "loss is  25.807728691101076\n",
            "Average step time is  0.07180484294891358\n",
            "i is  55200\n",
            "loss is  25.542618350982664\n",
            "Average step time is  0.07180087804794312\n",
            "i is  55300\n",
            "loss is  25.188921146392822\n",
            "Average step time is  0.07172521352767944\n",
            "i is  55400\n",
            "loss is  25.04245412826538\n",
            "Average step time is  0.07147919416427612\n",
            "i is  55500\n",
            "loss is  25.11249225616455\n",
            "Average step time is  0.07163618087768554\n",
            "i is  55600\n",
            "loss is  24.651337718963624\n",
            "Average step time is  0.07124741554260254\n",
            "i is  55700\n",
            "loss is  24.715521640777588\n",
            "Average step time is  0.07178771495819092\n",
            "i is  55800\n",
            "loss is  24.698424949645997\n",
            "Average step time is  0.0713917875289917\n",
            "i is  55900\n",
            "loss is  24.855030670166016\n",
            "Average step time is  0.07163646936416626\n",
            "i is  56000\n",
            "loss is  24.681119632720947\n",
            "Average step time is  0.0807955002784729\n",
            "i is  56100\n",
            "loss is  24.960316886901854\n",
            "Average step time is  0.07172504425048828\n",
            "i is  56200\n",
            "loss is  24.634150409698485\n",
            "Average step time is  0.07184859991073608\n",
            "i is  56300\n",
            "loss is  24.195430068969728\n",
            "Average step time is  0.07202365636825561\n",
            "i is  56400\n",
            "loss is  24.436888389587402\n",
            "Average step time is  0.0718872857093811\n",
            "i is  56500\n",
            "loss is  24.432377223968505\n",
            "Average step time is  0.07225537538528443\n",
            "i is  56600\n",
            "loss is  24.084898109436036\n",
            "Average step time is  0.0717842435836792\n",
            "i is  56700\n",
            "loss is  23.92794128417969\n",
            "Average step time is  0.0720644760131836\n",
            "i is  56800\n",
            "loss is  24.23945327758789\n",
            "Average step time is  0.07167100429534912\n",
            "i is  56900\n",
            "loss is  24.259347324371337\n",
            "Average step time is  0.07210403680801392\n",
            "i is  57000\n",
            "loss is  24.108524646759033\n",
            "Average step time is  0.07190686225891113\n",
            "i is  57100\n",
            "loss is  24.445181045532227\n",
            "Average step time is  0.07168769836425781\n",
            "i is  57200\n",
            "loss is  24.43914583206177\n",
            "Average step time is  0.07177582502365112\n",
            "i is  57300\n",
            "loss is  24.730006160736085\n",
            "Average step time is  0.07182643413543702\n",
            "i is  57400\n",
            "loss is  24.905076847076415\n",
            "Average step time is  0.07213649988174438\n",
            "i is  57500\n",
            "loss is  24.346040782928466\n",
            "Average step time is  0.0719827651977539\n",
            "i is  57600\n",
            "loss is  24.345461654663087\n",
            "Average step time is  0.0720976448059082\n",
            "i is  57700\n",
            "loss is  24.90046634674072\n",
            "Average step time is  0.07172749280929565\n",
            "i is  57800\n",
            "loss is  24.50218551635742\n",
            "Average step time is  0.07204826354980469\n",
            "i is  57900\n",
            "loss is  24.536946811676025\n",
            "Average step time is  0.07190427780151368\n",
            "i is  58000\n",
            "loss is  23.939884128570558\n",
            "Average step time is  0.07207902431488038\n",
            "i is  58100\n",
            "loss is  24.0723250579834\n",
            "Average step time is  0.07166807174682617\n",
            "i is  58200\n",
            "loss is  23.904592056274414\n",
            "Average step time is  0.07161406040191651\n",
            "i is  58300\n",
            "loss is  23.884311714172362\n",
            "Average step time is  0.07187746524810791\n",
            "i is  58400\n",
            "loss is  24.066406421661377\n",
            "Average step time is  0.07187048196792603\n",
            "i is  58500\n",
            "loss is  23.998383121490477\n",
            "Average step time is  0.0719726300239563\n",
            "i is  58600\n",
            "loss is  23.876544246673586\n",
            "Average step time is  0.07175346612930297\n",
            "i is  58700\n",
            "loss is  23.742571907043455\n",
            "Average step time is  0.07217399597167969\n",
            "i is  58800\n",
            "loss is  23.626335983276366\n",
            "Average step time is  0.07178453922271728\n",
            "i is  58900\n",
            "loss is  23.558917751312254\n",
            "Average step time is  0.07205386161804199\n",
            "i is  59000\n",
            "loss is  23.862053775787352\n",
            "Average step time is  0.07224003314971923\n",
            "i is  59100\n",
            "loss is  23.875223083496095\n",
            "Average step time is  0.0719349193572998\n",
            "i is  59200\n",
            "loss is  24.07277030944824\n",
            "Average step time is  0.07213356256484986\n",
            "i is  59300\n",
            "loss is  23.593860187530517\n",
            "Average step time is  0.07162522315979004\n",
            "i is  59400\n",
            "loss is  23.721887760162353\n",
            "Average step time is  0.07188170671463012\n",
            "i is  59500\n",
            "loss is  24.08270679473877\n",
            "Average step time is  0.07153161525726319\n",
            "i is  59600\n",
            "loss is  24.06485485076904\n",
            "Average step time is  0.07178768873214722\n",
            "i is  59700\n",
            "loss is  23.896549396514892\n",
            "Average step time is  0.07171031236648559\n",
            "i is  59800\n",
            "loss is  24.00588031768799\n",
            "Average step time is  0.07187192440032959\n",
            "i is  59900\n",
            "loss is  24.33162925720215\n",
            "Average step time is  0.07203299045562744\n",
            "i is  60000\n",
            "loss is  24.275517768859864\n",
            "Average step time is  0.07173280715942383\n",
            "i is  60100\n",
            "loss is  24.635763664245605\n",
            "Average step time is  0.07146261692047119\n",
            "i is  60200\n",
            "loss is  24.61161708831787\n",
            "Average step time is  0.071467444896698\n",
            "Completed 11 Epochs\n",
            "i is  60300\n",
            "loss is  26.019840087890625\n",
            "Average step time is  0.07146454334259034\n",
            "i is  60400\n",
            "loss is  25.150262432098387\n",
            "Average step time is  0.07208950996398926\n",
            "i is  60500\n",
            "loss is  25.097398567199708\n",
            "Average step time is  0.0716603946685791\n",
            "i is  60600\n",
            "loss is  25.452591094970703\n",
            "Average step time is  0.0719130802154541\n",
            "i is  60700\n",
            "loss is  25.014969940185548\n",
            "Average step time is  0.07185137033462524\n",
            "i is  60800\n",
            "loss is  24.56410280227661\n",
            "Average step time is  0.07135965824127197\n",
            "i is  60900\n",
            "loss is  24.618320083618165\n",
            "Average step time is  0.07176501274108887\n",
            "i is  61000\n",
            "loss is  24.44441423416138\n",
            "Average step time is  0.07161662101745606\n",
            "i is  61100\n",
            "loss is  24.123601036071776\n",
            "Average step time is  0.08052664041519166\n",
            "i is  61200\n",
            "loss is  24.478017196655273\n",
            "Average step time is  0.072151198387146\n",
            "i is  61300\n",
            "loss is  24.67766891479492\n",
            "Average step time is  0.07219267368316651\n",
            "i is  61400\n",
            "loss is  24.331527309417723\n",
            "Average step time is  0.07151511430740357\n",
            "i is  61500\n",
            "loss is  24.658516178131105\n",
            "Average step time is  0.071993408203125\n",
            "i is  61600\n",
            "loss is  24.96803035736084\n",
            "Average step time is  0.07181555509567261\n",
            "i is  61700\n",
            "loss is  24.18244468688965\n",
            "Average step time is  0.07233248710632324\n",
            "i is  61800\n",
            "loss is  24.109873428344727\n",
            "Average step time is  0.07196019411087036\n",
            "i is  61900\n",
            "loss is  24.092496490478517\n",
            "Average step time is  0.07241582870483398\n",
            "i is  62000\n",
            "loss is  23.910824661254882\n",
            "Average step time is  0.07254430770874024\n",
            "i is  62100\n",
            "loss is  23.85423366546631\n",
            "Average step time is  0.0722573733329773\n",
            "i is  62200\n",
            "loss is  23.949773921966553\n",
            "Average step time is  0.0719701075553894\n",
            "i is  62300\n",
            "loss is  23.953617649078367\n",
            "Average step time is  0.07255263805389404\n",
            "i is  62400\n",
            "loss is  23.61547382354736\n",
            "Average step time is  0.07185717105865479\n",
            "i is  62500\n",
            "loss is  23.91523151397705\n",
            "Average step time is  0.07164693117141724\n",
            "i is  62600\n",
            "loss is  24.18181457519531\n",
            "Average step time is  0.07171945333480835\n",
            "i is  62700\n",
            "loss is  23.952425594329835\n",
            "Average step time is  0.07205253601074219\n",
            "i is  62800\n",
            "loss is  24.115340099334716\n",
            "Average step time is  0.07192331075668335\n",
            "i is  62900\n",
            "loss is  24.408115959167482\n",
            "Average step time is  0.07177915334701539\n",
            "i is  63000\n",
            "loss is  23.907748851776123\n",
            "Average step time is  0.0719925856590271\n",
            "i is  63100\n",
            "loss is  24.007176837921143\n",
            "Average step time is  0.07228239536285401\n",
            "i is  63200\n",
            "loss is  24.078487339019777\n",
            "Average step time is  0.07181199550628663\n",
            "i is  63300\n",
            "loss is  24.290993156433107\n",
            "Average step time is  0.07189048528671264\n",
            "i is  63400\n",
            "loss is  24.283278770446778\n",
            "Average step time is  0.07203558444976807\n",
            "i is  63500\n",
            "loss is  23.68107936859131\n",
            "Average step time is  0.07193217039108277\n",
            "i is  63600\n",
            "loss is  23.564951992034914\n",
            "Average step time is  0.07211044311523437\n",
            "i is  63700\n",
            "loss is  23.433156032562255\n",
            "Average step time is  0.07194646596908569\n",
            "i is  63800\n",
            "loss is  23.778085689544678\n",
            "Average step time is  0.0719970703125\n",
            "i is  63900\n",
            "loss is  23.61149200439453\n",
            "Average step time is  0.07177149772644043\n",
            "i is  64000\n",
            "loss is  23.39905860900879\n",
            "Average step time is  0.07151358604431152\n",
            "i is  64100\n",
            "loss is  23.86959732055664\n",
            "Average step time is  0.07151964902877808\n",
            "i is  64200\n",
            "loss is  23.760810527801514\n",
            "Average step time is  0.0719101071357727\n",
            "i is  64300\n",
            "loss is  23.439245014190675\n",
            "Average step time is  0.0714104986190796\n",
            "i is  64400\n",
            "loss is  23.35677038192749\n",
            "Average step time is  0.07214317321777344\n",
            "i is  64500\n",
            "loss is  23.393395595550537\n",
            "Average step time is  0.0718634557723999\n",
            "i is  64600\n",
            "loss is  23.839492053985595\n",
            "Average step time is  0.07156786918640137\n",
            "i is  64700\n",
            "loss is  23.479912719726563\n",
            "Average step time is  0.07235796213150024\n",
            "i is  64800\n",
            "loss is  23.520805950164796\n",
            "Average step time is  0.0717803931236267\n",
            "i is  64900\n",
            "loss is  23.283729076385498\n",
            "Average step time is  0.07162111520767211\n",
            "i is  65000\n",
            "loss is  23.740810737609863\n",
            "Average step time is  0.07119802951812744\n",
            "i is  65100\n",
            "loss is  23.684790592193604\n",
            "Average step time is  0.07158245086669922\n",
            "i is  65200\n",
            "loss is  23.73057559967041\n",
            "Average step time is  0.07166069507598877\n",
            "i is  65300\n",
            "loss is  23.993763370513918\n",
            "Average step time is  0.07166091680526733\n",
            "i is  65400\n",
            "loss is  24.030856990814208\n",
            "Average step time is  0.07143338918685913\n",
            "i is  65500\n",
            "loss is  24.047236881256104\n",
            "Average step time is  0.07149616241455078\n",
            "i is  65600\n",
            "loss is  24.308809032440184\n",
            "Average step time is  0.07198490619659424\n",
            "Completed 12 Epochs\n",
            "i is  65700\n",
            "loss is  25.380894947052003\n",
            "Average step time is  0.07190093755722046\n",
            "i is  65800\n",
            "loss is  24.791094398498537\n",
            "Average step time is  0.07193506240844727\n",
            "i is  65900\n",
            "loss is  24.842909812927246\n",
            "Average step time is  0.07193150281906129\n",
            "i is  66000\n",
            "loss is  24.814749317169188\n",
            "Average step time is  0.07215917348861695\n",
            "i is  66100\n",
            "loss is  25.497381324768067\n",
            "Average step time is  0.07200279951095581\n",
            "i is  66200\n",
            "loss is  24.624399547576903\n",
            "Average step time is  0.08152290821075439\n",
            "i is  66300\n",
            "loss is  24.189734554290773\n",
            "Average step time is  0.07233183145523071\n",
            "i is  66400\n",
            "loss is  24.319634284973144\n",
            "Average step time is  0.07186650037765503\n",
            "i is  66500\n",
            "loss is  24.137207908630373\n",
            "Average step time is  0.07150524377822876\n",
            "i is  66600\n",
            "loss is  23.95215425491333\n",
            "Average step time is  0.07205852270126342\n",
            "i is  66700\n",
            "loss is  24.39928955078125\n",
            "Average step time is  0.07204754590988159\n",
            "i is  66800\n",
            "loss is  24.2829310798645\n",
            "Average step time is  0.07173426628112793\n",
            "i is  66900\n",
            "loss is  23.881372661590575\n",
            "Average step time is  0.07212705612182617\n",
            "i is  67000\n",
            "loss is  24.182468700408936\n",
            "Average step time is  0.07159613370895386\n",
            "i is  67100\n",
            "loss is  24.276978034973144\n",
            "Average step time is  0.07243090867996216\n",
            "i is  67200\n",
            "loss is  23.848902435302733\n",
            "Average step time is  0.07160415172576905\n",
            "i is  67300\n",
            "loss is  23.778764934539794\n",
            "Average step time is  0.07196341991424561\n",
            "i is  67400\n",
            "loss is  23.74684673309326\n",
            "Average step time is  0.0718772315979004\n",
            "i is  67500\n",
            "loss is  23.7266530418396\n",
            "Average step time is  0.07231785535812378\n",
            "i is  67600\n",
            "loss is  23.75530782699585\n",
            "Average step time is  0.07203397750854493\n",
            "i is  67700\n",
            "loss is  23.502098445892333\n",
            "Average step time is  0.07190178632736206\n",
            "i is  67800\n",
            "loss is  23.497242107391358\n",
            "Average step time is  0.07225990056991577\n",
            "i is  67900\n",
            "loss is  23.022451667785646\n",
            "Average step time is  0.07186049938201905\n",
            "i is  68000\n",
            "loss is  23.632178249359132\n",
            "Average step time is  0.07181199550628663\n",
            "i is  68100\n",
            "loss is  23.893545627593994\n",
            "Average step time is  0.07150355100631714\n",
            "i is  68200\n",
            "loss is  24.059760799407957\n",
            "Average step time is  0.07162304639816285\n",
            "i is  68300\n",
            "loss is  24.13137107849121\n",
            "Average step time is  0.071507728099823\n",
            "i is  68400\n",
            "loss is  23.98063106536865\n",
            "Average step time is  0.07209325790405273\n",
            "i is  68500\n",
            "loss is  23.62643892288208\n",
            "Average step time is  0.07217289447784424\n",
            "i is  68600\n",
            "loss is  23.938515930175782\n",
            "Average step time is  0.07161946535110474\n",
            "i is  68700\n",
            "loss is  23.807984714508056\n",
            "Average step time is  0.07156242370605469\n",
            "i is  68800\n",
            "loss is  23.968819904327393\n",
            "Average step time is  0.07156354188919067\n",
            "i is  68900\n",
            "loss is  23.723823699951172\n",
            "Average step time is  0.07191858530044555\n",
            "i is  69000\n",
            "loss is  23.285540294647216\n",
            "Average step time is  0.07131786346435547\n",
            "i is  69100\n",
            "loss is  23.094034633636475\n",
            "Average step time is  0.07213066577911377\n",
            "i is  69200\n",
            "loss is  23.462996940612793\n",
            "Average step time is  0.07152300119400025\n",
            "i is  69300\n",
            "loss is  23.518878898620606\n",
            "Average step time is  0.07162163019180298\n",
            "i is  69400\n",
            "loss is  23.54486436843872\n",
            "Average step time is  0.0716420316696167\n",
            "i is  69500\n",
            "loss is  23.389797592163085\n",
            "Average step time is  0.07153991937637329\n",
            "i is  69600\n",
            "loss is  23.382059345245363\n",
            "Average step time is  0.0718350076675415\n",
            "i is  69700\n",
            "loss is  23.34854452133179\n",
            "Average step time is  0.0719121527671814\n",
            "i is  69800\n",
            "loss is  23.166193351745605\n",
            "Average step time is  0.07182584762573242\n",
            "i is  69900\n",
            "loss is  23.276324577331543\n",
            "Average step time is  0.07147017240524292\n",
            "i is  70000\n",
            "loss is  23.120607471466066\n",
            "Average step time is  0.07157451629638673\n",
            "i is  70100\n",
            "loss is  23.484053325653075\n",
            "Average step time is  0.07181252002716064\n",
            "i is  70200\n",
            "loss is  23.15084104537964\n",
            "Average step time is  0.07168309926986695\n",
            "i is  70300\n",
            "loss is  23.138045082092287\n",
            "Average step time is  0.07176952123641968\n",
            "i is  70400\n",
            "loss is  23.136832313537596\n",
            "Average step time is  0.07214474678039551\n",
            "i is  70500\n",
            "loss is  23.49063056945801\n",
            "Average step time is  0.07232453823089599\n",
            "i is  70600\n",
            "loss is  23.266398906707764\n",
            "Average step time is  0.07204582929611206\n",
            "i is  70700\n",
            "loss is  23.333730812072755\n",
            "Average step time is  0.07223154783248902\n",
            "i is  70800\n",
            "loss is  23.421823463439942\n",
            "Average step time is  0.0721099591255188\n",
            "i is  70900\n",
            "loss is  23.911711502075196\n",
            "Average step time is  0.07223785638809205\n",
            "i is  71000\n",
            "loss is  23.747152118682862\n",
            "Average step time is  0.07253351926803589\n",
            "i is  71100\n",
            "loss is  23.925956649780275\n",
            "Average step time is  0.07222490787506103\n",
            "Completed 13 Epochs\n",
            "i is  71200\n",
            "loss is  24.892730236053467\n",
            "Average step time is  0.07214486837387085\n",
            "i is  71300\n",
            "loss is  24.526517372131348\n",
            "Average step time is  0.08142727136611938\n",
            "i is  71400\n",
            "loss is  24.531219596862794\n",
            "Average step time is  0.07239918947219849\n",
            "i is  71500\n",
            "loss is  24.616712894439697\n",
            "Average step time is  0.07230782508850098\n",
            "i is  71600\n",
            "loss is  24.279572944641114\n",
            "Average step time is  0.07206719160079957\n",
            "i is  71700\n",
            "loss is  24.22223815917969\n",
            "Average step time is  0.07259958505630493\n",
            "i is  71800\n",
            "loss is  23.928693885803224\n",
            "Average step time is  0.07217262506484985\n",
            "i is  71900\n",
            "loss is  24.183040466308594\n",
            "Average step time is  0.07202472448349\n",
            "i is  72000\n",
            "loss is  23.97644645690918\n",
            "Average step time is  0.07165863037109375\n",
            "i is  72100\n",
            "loss is  23.97966365814209\n",
            "Average step time is  0.07153074026107788\n",
            "i is  72200\n",
            "loss is  23.93668436050415\n",
            "Average step time is  0.07182617664337158\n",
            "i is  72300\n",
            "loss is  23.625675773620607\n",
            "Average step time is  0.07148575067520141\n",
            "i is  72400\n",
            "loss is  23.7824361038208\n",
            "Average step time is  0.07164687156677246\n",
            "i is  72500\n",
            "loss is  23.72690196990967\n",
            "Average step time is  0.0716531777381897\n",
            "i is  72600\n",
            "loss is  23.676927852630616\n",
            "Average step time is  0.07206234693527222\n",
            "i is  72700\n",
            "loss is  23.35322286605835\n",
            "Average step time is  0.07187828779220581\n",
            "i is  72800\n",
            "loss is  23.586027374267577\n",
            "Average step time is  0.07198991060256958\n",
            "i is  72900\n",
            "loss is  23.569693851470948\n",
            "Average step time is  0.07164746999740601\n",
            "i is  73000\n",
            "loss is  23.521117725372314\n",
            "Average step time is  0.07166395425796508\n",
            "i is  73100\n",
            "loss is  23.146341342926025\n",
            "Average step time is  0.07166309595108032\n",
            "i is  73200\n",
            "loss is  23.246883487701417\n",
            "Average step time is  0.07186461687088012\n",
            "i is  73300\n",
            "loss is  23.0342484664917\n",
            "Average step time is  0.07165783643722534\n",
            "i is  73400\n",
            "loss is  23.25796480178833\n",
            "Average step time is  0.07179739952087402\n",
            "i is  73500\n",
            "loss is  23.271749172210694\n",
            "Average step time is  0.07226186990737915\n",
            "i is  73600\n",
            "loss is  23.472315635681152\n",
            "Average step time is  0.07170073509216308\n",
            "i is  73700\n",
            "loss is  23.754704208374022\n",
            "Average step time is  0.07218722105026246\n",
            "i is  73800\n",
            "loss is  23.74014814376831\n",
            "Average step time is  0.0721084475517273\n",
            "i is  73900\n",
            "loss is  23.23001796722412\n",
            "Average step time is  0.07239837169647217\n",
            "i is  74000\n",
            "loss is  23.395787506103517\n",
            "Average step time is  0.07229304313659668\n",
            "i is  74100\n",
            "loss is  23.585504837036133\n",
            "Average step time is  0.07204737901687622\n",
            "i is  74200\n",
            "loss is  23.662257461547853\n",
            "Average step time is  0.07241676568984985\n",
            "i is  74300\n",
            "loss is  23.722163600921633\n",
            "Average step time is  0.07250086069107056\n",
            "i is  74400\n",
            "loss is  23.491856632232665\n",
            "Average step time is  0.07197392702102662\n",
            "i is  74500\n",
            "loss is  22.98965467453003\n",
            "Average step time is  0.07215248346328736\n",
            "i is  74600\n",
            "loss is  22.857184600830077\n",
            "Average step time is  0.07190642356872559\n",
            "i is  74700\n",
            "loss is  23.0315846824646\n",
            "Average step time is  0.07212997913360596\n",
            "i is  74800\n",
            "loss is  23.293403263092042\n",
            "Average step time is  0.07140951633453368\n",
            "i is  74900\n",
            "loss is  23.2659822845459\n",
            "Average step time is  0.0717233419418335\n",
            "i is  75000\n",
            "loss is  23.082579841613768\n",
            "Average step time is  0.07162344694137573\n",
            "i is  75100\n",
            "loss is  23.2185662651062\n",
            "Average step time is  0.0718692684173584\n",
            "i is  75200\n",
            "loss is  23.288255100250243\n",
            "Average step time is  0.07181618452072143\n",
            "i is  75300\n",
            "loss is  22.958463230133056\n",
            "Average step time is  0.07210032939910889\n",
            "i is  75400\n",
            "loss is  22.798436126708985\n",
            "Average step time is  0.07194881200790405\n",
            "i is  75500\n",
            "loss is  23.040067386627197\n",
            "Average step time is  0.07167823553085327\n",
            "i is  75600\n",
            "loss is  23.108797912597655\n",
            "Average step time is  0.07219879150390625\n",
            "i is  75700\n",
            "loss is  22.896025047302246\n",
            "Average step time is  0.07192597866058349\n",
            "i is  75800\n",
            "loss is  22.774638080596922\n",
            "Average step time is  0.07177337646484375\n",
            "i is  75900\n",
            "loss is  22.931704578399657\n",
            "Average step time is  0.07192442893981933\n",
            "i is  76000\n",
            "loss is  23.13245792388916\n",
            "Average step time is  0.07229140281677246\n",
            "i is  76100\n",
            "loss is  23.161505031585694\n",
            "Average step time is  0.07213556051254272\n",
            "i is  76200\n",
            "loss is  23.140182056427\n",
            "Average step time is  0.07189548254013062\n",
            "i is  76300\n",
            "loss is  23.294623012542726\n",
            "Average step time is  0.07192872285842895\n",
            "i is  76400\n",
            "loss is  23.405524730682373\n",
            "Average step time is  0.08159027338027953\n",
            "i is  76500\n",
            "loss is  23.615922355651854\n",
            "Average step time is  0.07235215187072754\n",
            "i is  76600\n",
            "loss is  23.7697407913208\n",
            "Average step time is  0.07188830614089965\n",
            "Completed 14 Epochs\n",
            "i is  76700\n",
            "loss is  25.047089557647706\n",
            "Average step time is  0.07189461946487427\n",
            "i is  76800\n",
            "loss is  24.264527111053468\n",
            "Average step time is  0.07236850500106812\n",
            "i is  76900\n",
            "loss is  24.150678310394287\n",
            "Average step time is  0.07184670925140381\n",
            "i is  77000\n",
            "loss is  24.360184745788573\n",
            "Average step time is  0.07252096176147461\n",
            "i is  77100\n",
            "loss is  24.21962038040161\n",
            "Average step time is  0.07262370586395264\n",
            "i is  77200\n",
            "loss is  23.852452297210693\n",
            "Average step time is  0.0719183349609375\n",
            "i is  77300\n",
            "loss is  23.7795707321167\n",
            "Average step time is  0.07240281820297241\n",
            "i is  77400\n",
            "loss is  23.91554132461548\n",
            "Average step time is  0.07262401342391968\n",
            "i is  77500\n",
            "loss is  23.440238609313965\n",
            "Average step time is  0.07261154413223267\n",
            "i is  77600\n",
            "loss is  23.681179065704345\n",
            "Average step time is  0.07308562278747559\n",
            "i is  77700\n",
            "loss is  23.678353710174562\n",
            "Average step time is  0.07277807474136352\n",
            "i is  77800\n",
            "loss is  23.1636660194397\n",
            "Average step time is  0.07245266437530518\n",
            "i is  77900\n",
            "loss is  23.65269884109497\n",
            "Average step time is  0.07267762899398804\n",
            "i is  78000\n",
            "loss is  23.679469966888426\n",
            "Average step time is  0.07263227462768555\n",
            "i is  78100\n",
            "loss is  23.541867542266846\n",
            "Average step time is  0.072882399559021\n",
            "i is  78200\n",
            "loss is  23.292952919006346\n",
            "Average step time is  0.07283795833587646\n",
            "i is  78300\n",
            "loss is  23.55487615585327\n",
            "Average step time is  0.07278185844421386\n",
            "i is  78400\n",
            "loss is  23.222522411346436\n",
            "Average step time is  0.07258950233459473\n",
            "i is  78500\n",
            "loss is  22.925324573516846\n",
            "Average step time is  0.07283267736434937\n",
            "i is  78600\n",
            "loss is  22.978395252227784\n",
            "Average step time is  0.0728797698020935\n",
            "i is  78700\n",
            "loss is  23.27684762954712\n",
            "Average step time is  0.07372105598449707\n",
            "i is  78800\n",
            "loss is  23.018864707946776\n",
            "Average step time is  0.07357018947601318\n",
            "i is  78900\n",
            "loss is  22.998087329864504\n",
            "Average step time is  0.07367727518081665\n",
            "i is  79000\n",
            "loss is  23.191950225830077\n",
            "Average step time is  0.07333787441253663\n",
            "i is  79100\n",
            "loss is  23.032214069366454\n",
            "Average step time is  0.07364023208618165\n",
            "i is  79200\n",
            "loss is  23.26386390686035\n",
            "Average step time is  0.07329190492630006\n",
            "i is  79300\n",
            "loss is  23.704574718475342\n",
            "Average step time is  0.07233470439910888\n",
            "i is  79400\n",
            "loss is  23.313824157714844\n",
            "Average step time is  0.07267736911773681\n",
            "i is  79500\n",
            "loss is  23.350637702941896\n",
            "Average step time is  0.07315904140472412\n",
            "i is  79600\n",
            "loss is  23.434935817718507\n",
            "Average step time is  0.07264876127243042\n",
            "i is  79700\n",
            "loss is  23.261293792724608\n",
            "Average step time is  0.07245854139328003\n",
            "i is  79800\n",
            "loss is  23.44246515274048\n",
            "Average step time is  0.07265212059020996\n",
            "i is  79900\n",
            "loss is  22.92718608856201\n",
            "Average step time is  0.07265971183776855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDjt0nXLz071",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# i is  98500\n",
        "# loss is  23.02226722717285\n",
        "# Average step time is  0.07153946399688721\n",
        "# Completed 18 Epochs\n",
        "# i is  98600"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVeXYszF5C7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del uAdagrad_switcher\n",
        "del vAdagrad_switcher"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlTualwp75od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del my_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyeIR7hQa-bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del vEmbed_switcher"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo1hFDcGdgbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del skip_gram_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvXtMOGt7szG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a266d5d-d7ce-4687-baa3-6069280ed797"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz8KCSnMIeAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numpyU = uEmbed_switcher.getNumpyVersion()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6AS9Ujbae9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del uEmbed_switcher"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlk0cms6RxV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uEmbed_switcher.saveCupy( 'uEmbedsFinal.npy.cpy')\n",
        "# # vEmbed_switcher.saveCupy( 'vEmbedsFinal.npy.cpy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR-AuhEHaksk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.save('testFile.npy',numpyU )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0w6wIcGx1nB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F2tjv9nAsKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHizOWr4x3_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/drive/My Drive/GoodReadsData/Lit2vec2p8Mil2.npy', numpyU )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw9AaFMoeyi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from google.colab import files\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7PM92BBe0l5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uploadModel = drive.CreateFile() \n",
        "uploadModel.SetContentFile('Lit2vec2p8Mil2.npy')\n",
        "uploadModel.Upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TBaNtHdqmR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_points = 400\n",
        "\n",
        "# tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')\n",
        "# two_d_embeddings = tsne.fit_transform(final_embeddings[1:num_points+1, :])\n",
        "# two_d_embeddingsSM = tsne.fit_transform(final_embeddingsSM[1:num_points+1, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un02WDWUBr1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def plot(embeddings, labels):\n",
        "#   assert embeddings.shape[0] >= len(labels), 'More labels than embeddings'\n",
        "#   pylab.figure(figsize=(50,50))  # in inches\n",
        "#   for i, label in enumerate(labels):\n",
        "#     x, y = embeddings[i,:]\n",
        "#     pylab.scatter(x, y)\n",
        "#     pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
        "#                    ha='right', va='bottom')\n",
        "#   pylab.show()\n",
        "\n",
        "# books = [bookDictionary[i] for i in range(1, num_points+1)]\n",
        "# plot(two_d_embeddings, books)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKd4EmLZEtD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def plot(softmax_weightsPlot, labels):\n",
        "#   assert softmax_weightsPlot.shape[0] >= len(labels), 'More labels than embeddings'\n",
        "#   pylab.figure(figsize=(50,50))  # in inches\n",
        "#   for i, label in enumerate(labels):\n",
        "#     x, y = softmax_weightsPlot[i,:]\n",
        "#     pylab.scatter(x, y)\n",
        "#     pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
        "#                    ha='right', va='bottom')\n",
        "#   pylab.show()\n",
        "\n",
        "# books = [bookDictionary[i] for i in range(1, num_points+1)]\n",
        "# plot(two_d_embeddingsSM, books)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}